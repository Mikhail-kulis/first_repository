{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Подключение-библиотек\" data-toc-modified-id=\"Подключение-библиотек-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Подключение библиотек</a></span></li><li><span><a href=\"#Регуляризация-комментариев\" data-toc-modified-id=\"Регуляризация-комментариев-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Регуляризация комментариев</a></span></li><li><span><a href=\"#Лемматизация-комментариев\" data-toc-modified-id=\"Лемматизация-комментариев-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Лемматизация комментариев</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Создание-выборок\" data-toc-modified-id=\"Создание-выборок-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Создание выборок</a></span></li><li><span><a href=\"#Модель-логистической-регрессии\" data-toc-modified-id=\"Модель-логистической-регрессии-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Модель логистической регрессии</a></span></li><li><span><a href=\"#Модель-случайного-леса\" data-toc-modified-id=\"Модель-случайного-леса-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Модель случайного леса</a></span></li><li><span><a href=\"#Модель-Catboost\" data-toc-modified-id=\"Модель-Catboost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Модель Catboost</a></span></li><li><span><a href=\"#Модель-LGBM\" data-toc-modified-id=\"Модель-LGBM-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Модель LGBM</a></span></li><li><span><a href=\"#Проверка-лучшей-модели-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-лучшей-модели-на-тестовой-выборке-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Проверка лучшей модели на тестовой выборке</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо классифицировать комментарии на токсичные и не токсичные. В распоряжении есть набор данных с разметкой о токсичности комментариев.\n",
    "\n",
    "Задачи:\n",
    "- подготовить данные\n",
    "- обучить разные модели и выбрать лучшую (модель со значением метрики качества *F1* не меньше 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Миша\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Миша\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression                    # импорт модели логистической регрессии\n",
    "from sklearn.ensemble import RandomForestClassifier                    # импорт модели случайного леса           \n",
    "from catboost import CatBoostClassifier                                # импорт модели CatBoost\n",
    "from lightgbm import LGBMClassifier                                    # импорт модели LGBM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")                                         # игнорируем предупреждения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('...')                                # чтение файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()                                                             # вывод информации о датафрейме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   Explanation\\nWhy the edits made under my usern...      0\n",
       "1   D'aww! He matches this background colour I'm s...      0\n",
       "2   Hey man, I'm really not trying to edit war. It...      0\n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4   You, sir, are my hero. Any chance you remember...      0\n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0\n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
       "7   Your vandalism to the Matt Shirvington article...      0\n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0\n",
       "9   alignment on this subject and which are contra...      0\n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0\n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0\n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1\n",
       "13  Before you start throwing accusations and warn...      0\n",
       "14  Oh, and the girl above started her arguments w...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)                                                           # вывод первых 15 строк датафрейма"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Пропуски не обнаружены, типы данных подходящие. Язык, на котором оставляют комментарии оказался английским, запомним это.\n",
    "\n",
    "Кроме того, есть подозрение несбалансированности классов токсичных и нетоксичных комментариев. Проверим это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество токсичных комментариев: 16225\n",
      "Количество нетоксичных комментариев: 143346\n"
     ]
    }
   ],
   "source": [
    "print('Количество токсичных комментариев:', data[data.toxic == 1]['toxic'].count())\n",
    "print('Количество нетоксичных комментариев:', data[data.toxic == 0]['toxic'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Действительно размеры классов отличаются, это необходимо учитывать при обучении некоторых моделей, которые чувствительны к дисбалансу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Регуляризация комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'] = data['text'].apply(lambda x: re.sub(r'[^a-zA-Z ]', ' ', x))    # замена ненужных символов на пробелы\n",
    "data['text'] = data['text'].apply(lambda x: x.lower())                        # приведение текста к нижнему регистру\n",
    "\n",
    "data['text'] = data['text'].apply(lambda x: x.split())                        # создание списка без множества пробелов\n",
    "data['text'] = data['text'].apply(lambda x: ' '.join(x))                      # сшивка комметариев\n",
    "data.head()                                                                   # проверка результата  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Ненужные символы отсутствуют."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лемматизация комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmtzr = WordNetLemmatizer()                                                  # вызов лемматизатора\n",
    "data['text'] = data['text'].apply(lambda x: nltk.word_tokenize(x))           # токенизация комментариев\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(                                           # лемматизация комментариев\n",
    "                    lambda lst:[lmtzr.lemmatize(word) for word in lst])      #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[d, aww, he, match, this, background, colour, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hey, man, i, m, really, not, trying, to, edit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[more, i, can, t, make, any, real, suggestion,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[congratulation, from, me, a, well, use, the, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[cocksucker, before, you, piss, around, on, my...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[your, vandalism, to, the, matt, shirvington, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[sorry, if, the, word, nonsense, wa, offensive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[alignment, on, this, subject, and, which, are...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[fair, use, rationale, for, image, wonju, jpg,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[bbq, be, a, man, and, let, discus, it, maybe,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[hey, what, is, it, talk, what, is, it, an, ex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[before, you, start, throwing, accusation, and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[oh, and, the, girl, above, started, her, argu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   [explanation, why, the, edits, made, under, my...      0\n",
       "1   [d, aww, he, match, this, background, colour, ...      0\n",
       "2   [hey, man, i, m, really, not, trying, to, edit...      0\n",
       "3   [more, i, can, t, make, any, real, suggestion,...      0\n",
       "4   [you, sir, are, my, hero, any, chance, you, re...      0\n",
       "5   [congratulation, from, me, a, well, use, the, ...      0\n",
       "6   [cocksucker, before, you, piss, around, on, my...      1\n",
       "7   [your, vandalism, to, the, matt, shirvington, ...      0\n",
       "8   [sorry, if, the, word, nonsense, wa, offensive...      0\n",
       "9   [alignment, on, this, subject, and, which, are...      0\n",
       "10  [fair, use, rationale, for, image, wonju, jpg,...      0\n",
       "11  [bbq, be, a, man, and, let, discus, it, maybe,...      0\n",
       "12  [hey, what, is, it, talk, what, is, it, an, ex...      1\n",
       "13  [before, you, start, throwing, accusation, and...      0\n",
       "14  [oh, and, the, girl, above, started, her, argu...      0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)                                                                # проверка результата                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: ' '.join(x))         # склейка комментариев"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>congratulation from me a well use the tool wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorry if the word nonsense wa offensive to you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fair use rationale for image wonju jpg thanks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq be a man and let discus it maybe over the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hey what is it talk what is it an exclusive gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>before you start throwing accusation and warni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oh and the girl above started her argument wit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   explanation why the edits made under my userna...      0\n",
       "1   d aww he match this background colour i m seem...      0\n",
       "2   hey man i m really not trying to edit war it s...      0\n",
       "3   more i can t make any real suggestion on impro...      0\n",
       "4   you sir are my hero any chance you remember wh...      0\n",
       "5   congratulation from me a well use the tool wel...      0\n",
       "6        cocksucker before you piss around on my work      1\n",
       "7   your vandalism to the matt shirvington article...      0\n",
       "8   sorry if the word nonsense wa offensive to you...      0\n",
       "9   alignment on this subject and which are contra...      0\n",
       "10  fair use rationale for image wonju jpg thanks ...      0\n",
       "11  bbq be a man and let discus it maybe over the ...      0\n",
       "12  hey what is it talk what is it an exclusive gr...      1\n",
       "13  before you start throwing accusation and warni...      0\n",
       "14  oh and the girl above started her argument wit...      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)                                                    # проверка результата"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Комментарии лемматизированы. Об этом свидетельсвует, например, комментарий с индексом 11. В нём присутствует слово 'let', которое в исходном нелемматизированном виды было 'lets'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 127671\n",
      "Размер валидационной выборки: 15942\n",
      "Размер тестовой выборки: 15958\n"
     ]
    }
   ],
   "source": [
    "train_valid, test = train_test_split(data, test_size = 0.1, random_state = 12345)      # в тестовую выборку идёт 10% данных\n",
    "train, valid = train_test_split(train_valid, test_size = 0.111, random_state = 12345)  # в валидационную выборку идёт 10% данных\n",
    "print(f'Размер обучающей выборки: {train.shape[0]}')\n",
    "print(f'Размер валидационной выборки: {valid.shape[0]}')\n",
    "print(f'Размер тестовой выборки: {test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train = train['text'].values.astype('U')                  # корпус обучающей выборки\n",
    "corpus_valid = valid['text'].values.astype('U')                  # корпус валидационной выборки\n",
    "corpus_test = test['text'].values.astype('U')                    # корпус тестовой выборки\n",
    "\n",
    "corpus_train_valid = train_valid['text'].values.astype('U')      # корпус выборки обучающая+валидационная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Миша\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))                 # в качестве стоп-слов выбираем английские\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)             # передаём счётчику TF-IDF стоп-слова\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = count_tf_idf.fit_transform(corpus_train)              # обучение и расчёт TF-IDF для корпуса обучающей выборки\n",
    "tf_idf_valid = count_tf_idf.transform(corpus_valid)                  # расчёт TF-IDF для корпуса валидационной выборки          \n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)                    # расчёт TF-IDF для корпуса тестовой выборки\n",
    "tf_idf_train_valid = count_tf_idf.transform(corpus_train_valid)      # расчёт TF-IDF для корпуса выборки обучающая+валидационная"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#КОД РЕВЬЮЕРА\n",
    "# tf_idf_train = count_tf_idf.fit_transform(corpus_train)           \n",
    "# tf_idf_valid = count_tf_idf.transform(corpus_valid)                         \n",
    "# tf_idf_test = count_tf_idf.transform(corpus_test)               \n",
    "# tf_idf_train_valid = count_tf_idf.transform(corpus_train_valid) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1: 0.7451923076923077\n"
     ]
    }
   ],
   "source": [
    "features_train = tf_idf_train\n",
    "target_train = train['toxic']\n",
    "\n",
    "features_valid = tf_idf_valid\n",
    "target_valid = valid['toxic']\n",
    "\n",
    "model = LogisticRegression(class_weight='balanced')   # модель логистической регрессии с учётом разных весов двух классов \n",
    "\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "predictions_1 = model.predict(features_valid)\n",
    "\n",
    "print(f'Метрика F1: {f1_score(target_valid, predictions_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель случайного леса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1: 0.6107644305772231\n"
     ]
    }
   ],
   "source": [
    "model_forest = RandomForestClassifier(random_state=12345, n_estimators=5, class_weight='balanced')  # модель случайного леса с\n",
    "# количеством деревьев 5 и учётом разных весов двух классов \n",
    "\n",
    "model_forest.fit(features_train, target_train)\n",
    "\n",
    "predictions_1 = model_forest.predict(features_valid)\n",
    "\n",
    "print(f'Метрика F1: {f1_score(target_valid, predictions_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2753481\ttotal: 11.5s\tremaining: 11m 19s\n",
      "1:\tlearn: 0.2311965\ttotal: 21.6s\tremaining: 10m 26s\n",
      "2:\tlearn: 0.2129660\ttotal: 33.5s\tremaining: 10m 36s\n",
      "3:\tlearn: 0.1982042\ttotal: 44.5s\tremaining: 10m 22s\n",
      "4:\tlearn: 0.1892004\ttotal: 56.6s\tremaining: 10m 22s\n",
      "5:\tlearn: 0.1833688\ttotal: 1m 7s\tremaining: 10m 5s\n",
      "6:\tlearn: 0.1777840\ttotal: 1m 17s\tremaining: 9m 44s\n",
      "7:\tlearn: 0.1714628\ttotal: 1m 29s\tremaining: 9m 44s\n",
      "8:\tlearn: 0.1674961\ttotal: 1m 42s\tremaining: 9m 39s\n",
      "9:\tlearn: 0.1647220\ttotal: 1m 52s\tremaining: 9m 24s\n",
      "10:\tlearn: 0.1607686\ttotal: 2m 4s\tremaining: 9m 14s\n",
      "11:\tlearn: 0.1583151\ttotal: 2m 14s\tremaining: 8m 59s\n",
      "12:\tlearn: 0.1551148\ttotal: 2m 25s\tremaining: 8m 46s\n",
      "13:\tlearn: 0.1530476\ttotal: 2m 36s\tremaining: 8m 35s\n",
      "14:\tlearn: 0.1508345\ttotal: 2m 43s\tremaining: 8m 9s\n",
      "15:\tlearn: 0.1485123\ttotal: 2m 53s\tremaining: 7m 56s\n",
      "16:\tlearn: 0.1462731\ttotal: 3m 1s\tremaining: 7m 38s\n",
      "17:\tlearn: 0.1445631\ttotal: 3m 8s\tremaining: 7m 20s\n",
      "18:\tlearn: 0.1427651\ttotal: 3m 14s\tremaining: 7m\n",
      "19:\tlearn: 0.1410842\ttotal: 3m 22s\tremaining: 6m 45s\n",
      "20:\tlearn: 0.1399491\ttotal: 3m 28s\tremaining: 6m 28s\n",
      "21:\tlearn: 0.1386463\ttotal: 3m 36s\tremaining: 6m 13s\n",
      "22:\tlearn: 0.1375872\ttotal: 3m 43s\tremaining: 5m 59s\n",
      "23:\tlearn: 0.1358431\ttotal: 3m 50s\tremaining: 5m 46s\n",
      "24:\tlearn: 0.1347187\ttotal: 3m 59s\tremaining: 5m 35s\n",
      "25:\tlearn: 0.1340189\ttotal: 4m 6s\tremaining: 5m 22s\n",
      "26:\tlearn: 0.1328611\ttotal: 4m 14s\tremaining: 5m 11s\n",
      "27:\tlearn: 0.1321271\ttotal: 4m 21s\tremaining: 4m 59s\n",
      "28:\tlearn: 0.1308373\ttotal: 4m 29s\tremaining: 4m 48s\n",
      "29:\tlearn: 0.1302194\ttotal: 4m 36s\tremaining: 4m 36s\n",
      "30:\tlearn: 0.1295676\ttotal: 4m 43s\tremaining: 4m 25s\n",
      "31:\tlearn: 0.1285791\ttotal: 4m 50s\tremaining: 4m 14s\n",
      "32:\tlearn: 0.1276993\ttotal: 4m 56s\tremaining: 4m 2s\n",
      "33:\tlearn: 0.1268352\ttotal: 5m 2s\tremaining: 3m 51s\n",
      "34:\tlearn: 0.1263219\ttotal: 5m 8s\tremaining: 3m 40s\n",
      "35:\tlearn: 0.1259055\ttotal: 5m 15s\tremaining: 3m 30s\n",
      "36:\tlearn: 0.1253857\ttotal: 5m 22s\tremaining: 3m 20s\n",
      "37:\tlearn: 0.1243882\ttotal: 5m 28s\tremaining: 3m 10s\n",
      "38:\tlearn: 0.1238786\ttotal: 5m 34s\tremaining: 3m\n",
      "39:\tlearn: 0.1234208\ttotal: 5m 40s\tremaining: 2m 50s\n",
      "40:\tlearn: 0.1230087\ttotal: 5m 47s\tremaining: 2m 40s\n",
      "41:\tlearn: 0.1224645\ttotal: 5m 53s\tremaining: 2m 31s\n",
      "42:\tlearn: 0.1216926\ttotal: 6m\tremaining: 2m 22s\n",
      "43:\tlearn: 0.1208834\ttotal: 6m 16s\tremaining: 2m 16s\n",
      "44:\tlearn: 0.1202865\ttotal: 6m 30s\tremaining: 2m 10s\n",
      "45:\tlearn: 0.1199138\ttotal: 6m 44s\tremaining: 2m 2s\n",
      "46:\tlearn: 0.1192126\ttotal: 6m 52s\tremaining: 1m 54s\n",
      "47:\tlearn: 0.1183808\ttotal: 6m 59s\tremaining: 1m 44s\n",
      "48:\tlearn: 0.1178530\ttotal: 7m 5s\tremaining: 1m 35s\n",
      "49:\tlearn: 0.1172136\ttotal: 7m 11s\tremaining: 1m 26s\n",
      "50:\tlearn: 0.1168623\ttotal: 7m 16s\tremaining: 1m 17s\n",
      "51:\tlearn: 0.1165080\ttotal: 7m 22s\tremaining: 1m 8s\n",
      "52:\tlearn: 0.1159025\ttotal: 7m 28s\tremaining: 59.3s\n",
      "53:\tlearn: 0.1150690\ttotal: 7m 34s\tremaining: 50.5s\n",
      "54:\tlearn: 0.1141437\ttotal: 7m 40s\tremaining: 41.9s\n",
      "55:\tlearn: 0.1138040\ttotal: 7m 47s\tremaining: 33.4s\n",
      "56:\tlearn: 0.1134278\ttotal: 7m 53s\tremaining: 24.9s\n",
      "57:\tlearn: 0.1130948\ttotal: 8m\tremaining: 16.6s\n",
      "58:\tlearn: 0.1127870\ttotal: 8m 6s\tremaining: 8.24s\n",
      "59:\tlearn: 0.1124849\ttotal: 8m 13s\tremaining: 0us\n",
      "Метрика F1 составила: 0.7538940809968848\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(loss_function=\"Logloss\", iterations=60, learning_rate = 0.8, max_depth = 8) # модель градиентого\n",
    "# бустинга Catboost с 60 итерациями, скоростью обучения 0.8 и максимальной глубиной дерева 8\n",
    "model.fit(features_train, target_train, verbose=1)                          # обучение модели Catboost на обучающей выборке\n",
    "\n",
    "predictions_1 = model.predict(features_valid)                               # построение предсказаний\n",
    "\n",
    "print(f'Метрика F1 составила: {f1_score(target_valid, predictions_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 составила: 0.7777003484320557\n"
     ]
    }
   ],
   "source": [
    "model = LGBMClassifier(n_estimators = 200)                       # модель LGBM с увеличенным количеством деревьев до 200\n",
    "\n",
    "model.fit(features_train, target_train)                          # обучение модели LGBM на обучающей выборке\n",
    "\n",
    "predictions_1 = model.predict(features_valid)                               # построение предсказаний\n",
    "\n",
    "print(f'Метрика F1 составила: {f1_score(target_valid, predictions_1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Лучшую метрику показала модель LGBM с увеличенным количеством деревьев до 200. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка лучшей модели на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика F1 составила: 0.7584789311408017\n"
     ]
    }
   ],
   "source": [
    "features_test = tf_idf_test                                               # признаки тестовой выборки\n",
    "target_test = test['toxic']                                               # целевой признак тестовой выборки\n",
    "\n",
    "features_train_valid = tf_idf_train_valid                                 # признаки выборки обучающая+валидационная\n",
    "target_train_valid = train_valid['toxic']                                 # целевой признак быборки обучающая+валидационная\n",
    "\n",
    "model.fit(features_train_valid, target_train_valid)                       # обучение лучшей модели \n",
    "\n",
    "predictions_2 = model.predict(features_test)                              # построение предсказаний\n",
    "\n",
    "print(f'Метрика F1 составила: {f1_score(target_test, predictions_2)}')    # вычисление метрики F1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе разработки метода оценки комментариев было выяснено, что комментарии на английском языке. Датафрейм с комментариями и правильной разметкой не содержал пропусков или неверных типов данных. Был обнаружен дисбаланс классов, что в дальнейшем учитывалось при построении моделей.\n",
    "\n",
    "Подготовка данных заключалась в регуляризации и лемматизации комментариев. Выделение признаков производилось с помощью вычисления TF-IDF. Счётчику были также переданы стоп-слова, которые были исключены из расчёта. После подготовки признаков для всех необходимых выборок были рассмотрены разные модели МО.\n",
    "- Логистическая регрессия с учётом дисбаланса: F1 = 0.75\n",
    "- Случайный лес с количеством деревьев 5 и учётом разных весов двух классов: F1 = 0.61\n",
    "\n",
    "Использование большого числа решающих деревьев приводит к долгому обучению, поэтому были рассмотрены модели град. бустинга\n",
    "Модели градиентного бустинга:\n",
    "- Catboost c 60 итерациями, скоростью обучения 0.8 и максимальной глубиной дерева 8: F1 = 0.75\n",
    "- LGBM c количеством деревьев 200: 0.78\n",
    "\n",
    "Лучшей моделью оказалась LGBM именно она отправилась на тест.\n",
    "\n",
    "Итоговое значение метрики F1 на тестовой выборке составило: 0.76"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 44,
    "start_time": "2022-06-10T14:09:35.405Z"
   },
   {
    "duration": 386,
    "start_time": "2022-06-10T14:09:38.178Z"
   },
   {
    "duration": 2471,
    "start_time": "2022-06-10T14:09:42.093Z"
   },
   {
    "duration": 13,
    "start_time": "2022-06-10T14:13:34.807Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-10T14:17:59.142Z"
   },
   {
    "duration": 7,
    "start_time": "2022-06-10T14:18:14.926Z"
   },
   {
    "duration": 27,
    "start_time": "2022-06-10T14:24:06.681Z"
   },
   {
    "duration": 851,
    "start_time": "2022-06-10T14:24:10.923Z"
   },
   {
    "duration": 43,
    "start_time": "2022-06-10T14:24:15.682Z"
   },
   {
    "duration": 50,
    "start_time": "2022-06-10T14:24:35.505Z"
   },
   {
    "duration": 45,
    "start_time": "2022-06-10T14:25:09.164Z"
   },
   {
    "duration": 438,
    "start_time": "2022-06-10T14:27:18.564Z"
   },
   {
    "duration": 52,
    "start_time": "2022-06-10T14:27:58.487Z"
   },
   {
    "duration": 1247,
    "start_time": "2022-06-10T14:28:02.751Z"
   },
   {
    "duration": 2362,
    "start_time": "2022-06-10T14:28:04.000Z"
   },
   {
    "duration": 31,
    "start_time": "2022-06-10T14:28:06.364Z"
   },
   {
    "duration": 14,
    "start_time": "2022-06-10T14:28:06.397Z"
   },
   {
    "duration": 55,
    "start_time": "2022-06-10T14:28:06.413Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
